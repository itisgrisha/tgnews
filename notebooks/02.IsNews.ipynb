{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ufal.udpipe import Model, Sentence, ProcessingError\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191101.tsv  20191106.tsv  20191111.tsv  20191116.tsv\t20191121.tsv\n",
      "20191102.tsv  20191107.tsv  20191112.tsv  20191117.tsv\t20191122.tsv\n",
      "20191103.tsv  20191108.tsv  20191113.tsv  20191118.tsv\t20191123.tsv\n",
      "20191104.tsv  20191109.tsv  20191114.tsv  20191119.tsv\t20191124.tsv\n",
      "20191105.tsv  20191110.tsv  20191115.tsv  20191120.tsv\t20191125.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls /eee/tgnews/meta/all_lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/eee/tgnews/meta/\"\n",
    "\n",
    "columns = [\"path\", \"og:site_name\", \"og:url\", \"og:title\"]\n",
    "\n",
    "table_ru = pd.read_csv(os.path.join(load_path, \"ru.tsv\"), sep='\\t', usecols=columns, keep_default_na=False, quoting=csv.QUOTE_NONE)\n",
    "table_en = pd.read_csv(os.path.join(load_path, \"en.tsv\"), sep='\\t', usecols=columns, keep_default_na=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделение токенов из url\n",
    "\n",
    "def url_to_tokens(url, lowercase=True, split_pattern=\"[^a-z]+\", filter_pattern=\"[a-z]{3,}\"):\n",
    "    \n",
    "    tokens = re.sub(\"https*://[^/]*\", \"\", url).strip(\"/\").split(\"/\")[:-1]\n",
    "    \n",
    "    if lowercase:\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "    if split_pattern is not None:\n",
    "        tokens = list(chain(*[re.split(split_pattern, token) for token in tokens]))\n",
    "        \n",
    "    if filter_pattern is not None:\n",
    "        tokens = list(filter(lambda x: re.search(filter_pattern, x), tokens))\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "table_ru[\"tokens:url\"] = table_ru[\"og:url\"].apply(url_to_tokens)\n",
    "table_en[\"tokens:url\"] = table_en[\"og:url\"].apply(url_to_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Формируем список наиболее частотных токенов\n",
    "\n",
    "site_tokens = dict([(site, Counter(tokens)) for site, tokens in table_ru.groupby(\"og:site_name\")[\"tokens:url\"].sum().iteritems()])\n",
    "\n",
    "for site, tokens in table_en.groupby(\"og:site_name\")[\"tokens:url\"].sum().iteritems():\n",
    "    \n",
    "    site_tokens.setdefault(site, Counter())\n",
    "    site_tokens[site] += Counter(tokens)\n",
    "    \n",
    "token_count = {}\n",
    "token_sites = {}\n",
    "\n",
    "for site, tokens in site_tokens.items():\n",
    "    for token, count in tokens.items():\n",
    "        \n",
    "        token_count.setdefault(token, 0)\n",
    "        token_count[token] += count\n",
    "        \n",
    "        token_sites.setdefault(token, [])\n",
    "        token_sites[token].append(site)\n",
    "        \n",
    "tokens = [token for token, count in token_count.items() if (count >= 100) and (len(token_sites[token]) >= 10)]\n",
    "\n",
    "with open(\"../url_tokens.txt\", \"w\") as fl:\n",
    "    fl.write('\\n'.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_token = \"recipes\"\n",
    "\n",
    "paths = table_ru[table_ru[\"tokens:url\"].apply(lambda x: url_token in x)][\"path\"].tolist()\n",
    "paths = paths + table_en[table_en[\"tokens:url\"].apply(lambda x: url_token in x)][\"path\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\"/>\n",
      "    <meta property=\"og:url\" content=\"https://www.telegraph.co.uk/recipes/0/seeded-crackersfor-cheese-recipe/\"/>\n",
      "    <meta property=\"og:site_name\" content=\"The Telegraph\"/>\n",
      "    <meta property=\"article:published_time\" content=\"2019-11-22T12:00:00+00:00\"/>\n",
      "    <meta property=\"og:title\" content=\"Seeded crackers for cheese recipe\"/>\n",
      "    <meta property=\"og:description\" content=\"There are some excellent ready-made crackers available (Peter&amp;rsquo;s Yard are my particular weakness), but there&amp;rsquo;s still something special about home-made ones, particularly if you present them with a whole soft cheese, or a good sized chunk of stilton or cheddar.\"/>\n",
      "  </head>\n",
      "  <body>\n",
      "    <article>\n",
      "      <h1>Seeded crackers for cheese recipe</h1>\n",
      "      <address><time datetime=\"2019-11-22T12:00:00+00:00\">22 Nov 2019, 12:00</time> by <a rel=\"author\" href=\"https://www.telegraph.co.uk/authors/xanthe-clay/\" target=\"_blank\">Xanthe Clay</a></address>\n",
      "      <p>There are some excellent ready-made crackers available (Peter’s Yard are my particular weakness), but there’s still something special about home-made ones, particularly if you present them with a whole soft cheese, or a good sized chunk of stilton or cheddar. </p>\n",
      "      <p><b>Prep time</b>: 25 minutes | <b>Cooking time</b>: 15 minutes</p>\n",
      "      <h3>MAKES</h3>\n",
      "      <p>About 36 crackers </p>\n",
      "      <h3>INGREDIENTS</h3>\n",
      "      <ul>\n",
      "        <li>100g wholemeal flour</li>\n",
      "        <li>100g plain white flour</li>\n",
      "        <li>30g rye flour</li>\n",
      "        <li>10g salt</li>\n",
      "        <li>100ml water</li>\n",
      "        <li>3 tbsp olive oil</li>\n",
      "        <li>200g mixed seeds – I use pumpkin, sunflower, sesame and linseed</li>\n",
      "        <li>3 tbsp poppy seeds (optional)</li>\n",
      "      </ul>\n",
      "      <h3>METHOD</h3>\n",
      "      <ol>\n",
      "        <li>Preheat the oven to 200C/180C fan/Gas 6. In a large bowl, mix all three flours, the salt, water, olive oil, and most of the mixed seeds (save two tablespoons for scattering over the top). Knead lightly to make a dough. </li>\n",
      "        <li>Roll out half to a 30 x 30cm square on a piece of non-stick parchment. It will be crumbly – all those seeds – so trim the edges to a neatish square and use the trimmings to patch any cracks. Still on the paper, cut into six long strips, and then across into three, making 18 roughly 5 x 10cm crackers. </li>\n",
      "        <li>Brush with water and sprinkle with half the reserved seeds and the poppy seeds, if you are using them. Slide the crackers, still on the paper, on to a large baking sheet. Repeat with the other half of the dough. </li>\n",
      "        <li>Bake for 15 minutes, turning the baking sheets halfway through, until the crackers are pale gold.</li>\n",
      "        <li>Slide on to a cooling rack, and once cool break into separate crackers. Store in an airtight container. </li>\n",
      "      </ol>\n",
      "    </article>\n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "with open(paths[np.random.choice(range(len(paths)))]) as fl:\n",
    "    print(fl.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#По ключевым словам из url определяем является ли статья новостью и формируем обуч. выборку\n",
    "\n",
    "def predict_is_news_by_url(url_tokens):\n",
    "    \n",
    "    url_tokens = \" \".join(url_tokens)\n",
    "    \n",
    "    for part in [\"news\",\n",
    "                 \"novosti\"]:\n",
    "    \n",
    "        if part in url_tokens:\n",
    "            return 1\n",
    "        \n",
    "    for part in [\"fashion\",\n",
    "                 \"style\",\n",
    "                 \"beauty\",\n",
    "                 \"trend\",\n",
    "                 \"sex\",\n",
    "                 \"recipe\"]:\n",
    "    \n",
    "        if part in url_tokens:\n",
    "            return 0\n",
    "    \n",
    "    return None\n",
    "\n",
    "table_ru[\"is_news\"] = table_ru[\"tokens:url\"].apply(predict_is_news_by_url)\n",
    "table_en[\"is_news\"] = table_en[\"tokens:url\"].apply(predict_is_news_by_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считываем разметку\n",
    "\n",
    "table_ru = table_ru.set_index('og:url')\n",
    "table_en = table_en.set_index('og:url')\n",
    "\n",
    "for table_name in os.listdir(\"../articles_with_true_is_news\"):\n",
    "    \n",
    "    table_with_true_is_news = pd.read_csv(os.path.join(\"../articles_with_true_is_news\", table_name)).set_index(\"og:url\")\n",
    "    \n",
    "    table_ru.update(table_with_true_is_news)\n",
    "    table_en.update(table_with_true_is_news)\n",
    "    \n",
    "table_ru = table_ru.reset_index()\n",
    "table_en = table_en.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаляем 100000 строчек с is_news == 1\n",
    "\n",
    "table_ru = table_ru.drop(np.random.choice(table_ru[table_ru[\"is_news\"] == 1].index, 100000))\n",
    "table_en = table_en.drop(np.random.choice(table_en[table_en[\"is_news\"] == 1].index, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1.0: 53577, 0.0: 1619}), Counter({0.0: 2557, 1.0: 23251}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(table_ru[\"is_news\"].dropna()), Counter(table_en[\"is_news\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаляем 100000 строчек с is_news == None\n",
    "\n",
    "table_ru = table_ru.drop(np.random.choice(table_ru[table_ru[\"is_news\"].isna()].index, 100000))\n",
    "table_en = table_en.drop(np.random.choice(table_en[table_en[\"is_news\"].isna()].index, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71009, 77030)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(table_ru[\"is_news\"].isna()), sum(table_en[\"is_news\"].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем пользоваться данными предобработанными с помощью команд:\n",
    "\n",
    "python preproc_udpipe.py /eee/tgnews/misc/ru.udpipe /eee/tgnews/meta/ru.tsv /eee/tgnews/meta/ru_preproc.csv 10 path og:title text\n",
    "\n",
    "python preproc_udpipe.py /eee/tgnews/misc/en.udpipe /eee/tgnews/meta/en.tsv /eee/tgnews/meta/en_preproc.csv 10 path og:title text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем предобработанные тексты\n",
    "\n",
    "table_ru = table_ru.join(pd.read_csv(os.path.join(load_path, \"ru_preproc.csv\"), keep_default_na=False).set_index(\"path\"), \n",
    "                         on=\"path\", rsuffix=\"_preproc\")\n",
    "table_en = table_en.join(pd.read_csv(os.path.join(load_path, \"en_preproc.csv\"), keep_default_na=False).set_index(\"path\"), \n",
    "                         on=\"path\", rsuffix=\"_preproc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Извлечение предложений из формата conllu\n",
    "\n",
    "udpipe_model = Model.load('/eee/tgnews/misc/ru.udpipe')\n",
    "conllu_tokenizer = udpipe_model.newTokenizer(\"conllu\").newConlluInputFormat()\n",
    "\n",
    "def conllu_encode(conllu_text):\n",
    "    \n",
    "    sentence = Sentence()\n",
    "    error = ProcessingError()\n",
    "    \n",
    "    conllu_tokenizer.setText(conllu_text)\n",
    "    \n",
    "    sentences = []\n",
    "    while conllu_tokenizer.nextSentence(sentence, error):\n",
    "        sentences.append(sentence.words[1:]) \n",
    "        \n",
    "    return sentences\n",
    "\n",
    "table_ru[\"og:title_preproc\"] = table_ru[\"og:title_preproc\"].apply(conllu_encode)\n",
    "table_ru[\"text\"] = table_ru[\"text\"].apply(conllu_encode)\n",
    "\n",
    "table_en[\"og:title_preproc\"] = table_en[\"og:title_preproc\"].apply(conllu_encode)\n",
    "table_en[\"text\"] = table_en[\"text\"].apply(conllu_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_na_ru = table_ru[\"is_news\"].isna()\n",
    "flags_na_en = table_en[\"is_news\"].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование текста в вектор признаков (морфология)\n",
    "\n",
    "with open(\"../morph_list/Upostags.txt\") as fl:\n",
    "    upostag_map = fl.read().split('\\n')\n",
    "    \n",
    "with open(\"../morph_list/Feats.txt\") as fl:\n",
    "    feat_map = fl.read().split('\\n')\n",
    "    \n",
    "upostag_map = dict(zip(upostag_map, range(len(upostag_map))))\n",
    "feat_map = dict(zip(feat_map, range(len(feat_map))))\n",
    "\n",
    "def get_vec(item_map, items):\n",
    "    \n",
    "    vec = np.zeros(len(item_map))\n",
    "    \n",
    "    if not len(items):\n",
    "        return vec\n",
    "    \n",
    "    n_items = 0\n",
    "    for item in items:\n",
    "        \n",
    "        if item in item_map:\n",
    "            \n",
    "            vec[item_map[item]] += 1\n",
    "            n_items += 1\n",
    "            \n",
    "    return vec / n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Валидация логистической регрессии\n",
    "\n",
    "def validation(X, y, penalty=\"l2\", l1_ratio=0):\n",
    "    \n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        lr = LogisticRegression(penalty=penalty, l1_ratio=l1_ratio, solver='saga', class_weight='balanced', n_jobs=-1).fit(X_train, y_train)\n",
    "        scores.append(balanced_accuracy_score(y_test, lr.predict(X_test)))\n",
    "\n",
    "    print(f\"balanced_accuracy: {sum(scores) / len(scores)}\\n\")\n",
    "    print(classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подбор комбинации признаков\n",
    "\n",
    "def feature(table, y):\n",
    "    \n",
    "    title_upostag = table[\"og:title_preproc\"].apply(lambda x: [[word.upostag for word in sent] for sent in x]) \\\n",
    "                                             .apply(lambda x: get_vec(upostag_map, list(chain(*x))))\n",
    "\n",
    "    title_upostag = np.array(title_upostag.tolist())\n",
    "    \n",
    "    text_upostag = table[\"text\"].apply(lambda x: [[word.upostag for word in sent] for sent in x]) \\\n",
    "                                .apply(lambda x: get_vec(upostag_map, list(chain(*x))))\n",
    "\n",
    "    text_upostag = np.array(text_upostag.tolist())\n",
    "    \n",
    "    title_text_upostag = (table[\"og:title_preproc\"].apply(lambda x: [[word.upostag for word in sent] for sent in x]) + \\\n",
    "                          table[\"text\"].apply(lambda x: [[word.upostag for word in sent] for sent in x]))\n",
    "\n",
    "    title_text_upostag = title_text_upostag.apply(lambda x: get_vec(upostag_map, list(chain(*x))))\n",
    "    title_text_upostag = np.array(title_text_upostag.tolist())\n",
    "    \n",
    "    title_feats = table[\"og:title_preproc\"].apply(lambda x: [[word.feats.split(\"|\") for word in sent if word.feats] for sent in x]) \\\n",
    "                                           .apply(lambda x: [list(chain(*sent)) for sent in x]) \\\n",
    "                                           .apply(lambda x: get_vec(feat_map, list(chain(*x))))\n",
    "\n",
    "    title_feats = np.array(title_feats.tolist())\n",
    "    \n",
    "    text_feats = table[\"text\"].apply(lambda x: [[word.feats.split(\"|\") for word in sent if word.feats] for sent in x]) \\\n",
    "                              .apply(lambda x: [list(chain(*sent)) for sent in x]) \\\n",
    "                              .apply(lambda x: get_vec(feat_map, list(chain(*x))))\n",
    "\n",
    "    text_feats = np.array(text_feats.tolist())\n",
    "    \n",
    "    title_text_feats = (table[\"og:title_preproc\"].apply(lambda x: [[word.feats.split(\"|\") for word in sent if word.feats] for sent in x]) \\\n",
    "                                                 .apply(lambda x: [list(chain(*sent)) for sent in x]) + \\\n",
    "                        table[\"text\"].apply(lambda x: [[word.feats.split(\"|\") for word in sent if word.feats] for sent in x]) \\\n",
    "                                     .apply(lambda x: [list(chain(*sent)) for sent in x]))\n",
    "\n",
    "    title_text_feats = title_text_feats.apply(lambda x: get_vec(feat_map, list(chain(*x))))\n",
    "    title_text_feats = np.array(title_text_feats.tolist())\n",
    "    \n",
    "    print(\"titles upostag\")\n",
    "    validation(title_upostag, y)\n",
    "    \n",
    "    print(\"texts upostag\")\n",
    "    validation(text_upostag, y)\n",
    "    \n",
    "    print(\"sum titles texts upostag\")\n",
    "    validation((title_upostag + text_upostag) / 2, y)\n",
    "\n",
    "    print(\"concat titles and texts upostag \")\n",
    "    validation(np.concatenate([title_upostag, text_upostag], axis=1) / 2, y)\n",
    "    \n",
    "    print(\"join titles and texts upostag\")\n",
    "    validation(title_text_upostag, y)\n",
    "    \n",
    "    print(\"titles feats\")\n",
    "    validation(title_feats, y)\n",
    "    \n",
    "    print(\"texts feats\")\n",
    "    validation(text_feats, y)\n",
    "    \n",
    "    print(\"sum titles texts feats\")\n",
    "    validation((title_feats + text_feats) / 2, y)\n",
    "\n",
    "    print(\"concat titles and texts feats \")\n",
    "    validation(np.concatenate([title_feats, text_feats], axis=1) / 2, y)\n",
    "    \n",
    "    print(\"join titles and texts feats\")\n",
    "    validation(title_text_feats, y)\n",
    "    \n",
    "    print(\"concat titles upostag and titles feats\")\n",
    "    validation(np.concatenate([title_upostag, title_feats], axis=1) / 2, y)\n",
    "    \n",
    "    print(\"concat texts upostag and texts feats\")\n",
    "    validation(np.concatenate([text_upostag, text_feats], axis=1) / 2, y)\n",
    "    \n",
    "    print(\"concat titles, texts upostag and texts feats\")\n",
    "    validation(np.concatenate([title_upostag, text_upostag, text_feats], axis=1) / 3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение модели\n",
    "\n",
    "def dump_model(model, scaler, path):\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    \n",
    "    num_coeffs = model.coef_.size\n",
    "    \n",
    "    if scaler is None:\n",
    "        scaler = namedtuple('DummyScaler', ['mean_', 'scale_'])(np.zeros(num_coeffs), np.ones(num_coeffs))\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        f.write(f'{model.coef_.shape[1]}\\n')\n",
    "        f.write(f'{model.intercept_[0]}\\n')\n",
    "        for c, m, s in zip(model.coef_.flatten(), scaler.mean_.flatten(), scaler.scale_.flatten()):\n",
    "            f.write(f'{c} {m} {s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ru**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table_ru[~flags_na_ru]\n",
    "y = table[\"is_news\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles upostag\n",
      "balanced_accuracy: 0.6865171523774437\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.76      0.12       160\n",
      "         1.0       0.99      0.66      0.79      5341\n",
      "\n",
      "    accuracy                           0.66      5501\n",
      "   macro avg       0.53      0.71      0.45      5501\n",
      "weighted avg       0.96      0.66      0.77      5501\n",
      "\n",
      "texts upostag\n",
      "balanced_accuracy: 0.6959547725328192\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      0.69      0.14       160\n",
      "         1.0       0.99      0.75      0.85      5341\n",
      "\n",
      "    accuracy                           0.75      5501\n",
      "   macro avg       0.53      0.72      0.50      5501\n",
      "weighted avg       0.96      0.75      0.83      5501\n",
      "\n",
      "sum titles texts upostag\n",
      "balanced_accuracy: 0.7040129450767412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.03      0.99      0.07       160\n",
      "         1.0       1.00      0.17      0.29      5341\n",
      "\n",
      "    accuracy                           0.20      5501\n",
      "   macro avg       0.52      0.58      0.18      5501\n",
      "weighted avg       0.97      0.20      0.29      5501\n",
      "\n",
      "concat titles and texts upostag \n",
      "balanced_accuracy: 0.7052219290221861\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.03      0.04       160\n",
      "         1.0       0.97      1.00      0.98      5341\n",
      "\n",
      "    accuracy                           0.97      5501\n",
      "   macro avg       0.58      0.51      0.51      5501\n",
      "weighted avg       0.95      0.97      0.96      5501\n",
      "\n",
      "join titles and texts upostag\n",
      "balanced_accuracy: 0.7180906264053404\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.81      0.12       160\n",
      "         1.0       0.99      0.64      0.78      5341\n",
      "\n",
      "    accuracy                           0.64      5501\n",
      "   macro avg       0.53      0.72      0.45      5501\n",
      "weighted avg       0.96      0.64      0.76      5501\n",
      "\n",
      "titles feats\n",
      "balanced_accuracy: 0.6790522171408025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.03      0.99      0.06       160\n",
      "         1.0       0.99      0.07      0.13      5341\n",
      "\n",
      "    accuracy                           0.10      5501\n",
      "   macro avg       0.51      0.53      0.09      5501\n",
      "weighted avg       0.97      0.10      0.13      5501\n",
      "\n",
      "texts feats\n",
      "balanced_accuracy: 0.7008337841671228\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.91      0.10       160\n",
      "         1.0       0.99      0.51      0.68      5341\n",
      "\n",
      "    accuracy                           0.52      5501\n",
      "   macro avg       0.52      0.71      0.39      5501\n",
      "weighted avg       0.97      0.52      0.66      5501\n",
      "\n",
      "sum titles texts feats\n",
      "balanced_accuracy: 0.7293418742976068\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      0.75      0.15       160\n",
      "         1.0       0.99      0.76      0.86      5341\n",
      "\n",
      "    accuracy                           0.76      5501\n",
      "   macro avg       0.54      0.75      0.50      5501\n",
      "weighted avg       0.96      0.76      0.84      5501\n",
      "\n",
      "concat titles and texts feats \n",
      "balanced_accuracy: 0.7093452897306954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.89      0.10       160\n",
      "         1.0       0.99      0.50      0.66      5341\n",
      "\n",
      "    accuracy                           0.51      5501\n",
      "   macro avg       0.52      0.70      0.38      5501\n",
      "weighted avg       0.97      0.51      0.65      5501\n",
      "\n",
      "join titles and texts feats\n",
      "balanced_accuracy: 0.7582890446353472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.10      0.81      0.17       160\n",
      "         1.0       0.99      0.78      0.87      5341\n",
      "\n",
      "    accuracy                           0.78      5501\n",
      "   macro avg       0.55      0.79      0.52      5501\n",
      "weighted avg       0.97      0.78      0.85      5501\n",
      "\n",
      "concat titles upostag and titles feats\n",
      "balanced_accuracy: 0.6830405780090117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.84      0.11       160\n",
      "         1.0       0.99      0.61      0.75      5341\n",
      "\n",
      "    accuracy                           0.61      5501\n",
      "   macro avg       0.53      0.72      0.43      5501\n",
      "weighted avg       0.96      0.61      0.74      5501\n",
      "\n",
      "concat texts upostag and texts feats\n",
      "balanced_accuracy: 0.7477841136245915\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      0.84      0.14       160\n",
      "         1.0       0.99      0.70      0.82      5341\n",
      "\n",
      "    accuracy                           0.70      5501\n",
      "   macro avg       0.53      0.77      0.48      5501\n",
      "weighted avg       0.97      0.70      0.80      5501\n",
      "\n",
      "concat titles, texts upostag and texts feats\n",
      "balanced_accuracy: 0.7119632220002756\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       160\n",
      "         1.0       0.97      1.00      0.99      5341\n",
      "\n",
      "    accuracy                           0.97      5501\n",
      "   macro avg       0.49      0.50      0.49      5501\n",
      "weighted avg       0.94      0.97      0.96      5501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature(table, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(table):\n",
    "\n",
    "    text_feats = table[\"text\"].apply(lambda x: [[word.feats.split(\"|\") for word in sent if word.feats] for sent in x]) \\\n",
    "                              .apply(lambda x: [list(chain(*sent)) for sent in x]) \\\n",
    "                              .apply(lambda x: get_vec(feat_map, list(chain(*x))))\n",
    "\n",
    "    return np.array(text_feats.tolist())\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', solver='saga', n_jobs=-1)\n",
    "lr.fit(X(table), y)\n",
    "\n",
    "dump_model(model=lr, scaler=None, path=\"../models/news_model_ru.logreg\")\n",
    "pickle.dump(lr, open(\"../models/news_model_ru.logreg.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание на неразмеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table_ru[flags_na_ru]\n",
    "table[\"predict\"] = lr.predict_proba(X(table))[:, 1]\n",
    "\n",
    "b1 = 0.25\n",
    "b2 = 0.35\n",
    "\n",
    "table_middle = table[(table[\"predict\"] > b1) & (table[\"predict\"] < b2)]\n",
    "\n",
    "table_middle = table_middle[[\"path\", \"og:url\", \"predict\"]].join(pd.concat([table_ru[[\"path\", \"og:title\"]], table_en[[\"path\", \"og:title\"]]], \n",
    "                                                                          ignore_index=True, axis=0).set_index(\"path\"), on=\"path\")\n",
    "\n",
    "table_middle = table_middle[[\"og:url\", \"og:title\", \"predict\"]]\n",
    "table_middle[\"is_news\"] = 1\n",
    "\n",
    "table_middle.sort_values(\"predict\").to_excel(\"../articles_with_true_is_news_ru.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**en**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table_en[~flags_na_en]\n",
    "y = table[\"is_news\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles upostag\n",
      "balanced_accuracy: 0.6455908274576098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.55      0.23       246\n",
      "         1.0       0.93      0.66      0.77      2345\n",
      "\n",
      "    accuracy                           0.65      2591\n",
      "   macro avg       0.54      0.61      0.50      2591\n",
      "weighted avg       0.86      0.65      0.72      2591\n",
      "\n",
      "texts upostag\n",
      "balanced_accuracy: 0.6991939113531349\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.69      0.29       246\n",
      "         1.0       0.95      0.68      0.80      2345\n",
      "\n",
      "    accuracy                           0.68      2591\n",
      "   macro avg       0.57      0.68      0.54      2591\n",
      "weighted avg       0.88      0.68      0.75      2591\n",
      "\n",
      "sum titles texts upostag\n",
      "balanced_accuracy: 0.6594081458388381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.56      0.23       246\n",
      "         1.0       0.93      0.66      0.77      2345\n",
      "\n",
      "    accuracy                           0.65      2591\n",
      "   macro avg       0.54      0.61      0.50      2591\n",
      "weighted avg       0.86      0.65      0.72      2591\n",
      "\n",
      "concat titles and texts upostag \n",
      "balanced_accuracy: 0.6929932490270451\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.62      0.28       246\n",
      "         1.0       0.95      0.71      0.81      2345\n",
      "\n",
      "    accuracy                           0.70      2591\n",
      "   macro avg       0.56      0.66      0.54      2591\n",
      "weighted avg       0.87      0.70      0.76      2591\n",
      "\n",
      "join titles and texts upostag\n",
      "balanced_accuracy: 0.7024737027384809\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.67      0.29       246\n",
      "         1.0       0.95      0.69      0.80      2345\n",
      "\n",
      "    accuracy                           0.69      2591\n",
      "   macro avg       0.57      0.68      0.54      2591\n",
      "weighted avg       0.88      0.69      0.75      2591\n",
      "\n",
      "titles feats\n",
      "balanced_accuracy: 0.647792461932223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.16      0.54      0.24       246\n",
      "         1.0       0.94      0.70      0.80      2345\n",
      "\n",
      "    accuracy                           0.68      2591\n",
      "   macro avg       0.55      0.62      0.52      2591\n",
      "weighted avg       0.86      0.68      0.75      2591\n",
      "\n",
      "texts feats\n",
      "balanced_accuracy: 0.7125241914930645\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.68      0.31       246\n",
      "         1.0       0.95      0.71      0.82      2345\n",
      "\n",
      "    accuracy                           0.71      2591\n",
      "   macro avg       0.58      0.70      0.56      2591\n",
      "weighted avg       0.88      0.71      0.77      2591\n",
      "\n",
      "sum titles texts feats\n",
      "balanced_accuracy: 0.6677983138405035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.59      0.26       246\n",
      "         1.0       0.94      0.69      0.80      2345\n",
      "\n",
      "    accuracy                           0.68      2591\n",
      "   macro avg       0.55      0.64      0.53      2591\n",
      "weighted avg       0.87      0.68      0.75      2591\n",
      "\n",
      "concat titles and texts feats \n",
      "balanced_accuracy: 0.7018663516768575\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.19      0.60      0.29       246\n",
      "         1.0       0.95      0.74      0.83      2345\n",
      "\n",
      "    accuracy                           0.72      2591\n",
      "   macro avg       0.57      0.67      0.56      2591\n",
      "weighted avg       0.87      0.72      0.78      2591\n",
      "\n",
      "join titles and texts feats\n",
      "balanced_accuracy: 0.7094817117994451\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.21      0.70      0.32       246\n",
      "         1.0       0.96      0.72      0.82      2345\n",
      "\n",
      "    accuracy                           0.72      2591\n",
      "   macro avg       0.58      0.71      0.57      2591\n",
      "weighted avg       0.89      0.72      0.78      2591\n",
      "\n",
      "concat titles upostag and titles feats\n",
      "balanced_accuracy: 0.6575278121381466\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.55      0.24       246\n",
      "         1.0       0.94      0.68      0.79      2345\n",
      "\n",
      "    accuracy                           0.67      2591\n",
      "   macro avg       0.54      0.61      0.51      2591\n",
      "weighted avg       0.86      0.67      0.74      2591\n",
      "\n",
      "concat texts upostag and texts feats\n",
      "balanced_accuracy: 0.7157515175138213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.68      0.31       246\n",
      "         1.0       0.96      0.71      0.82      2345\n",
      "\n",
      "    accuracy                           0.71      2591\n",
      "   macro avg       0.58      0.70      0.56      2591\n",
      "weighted avg       0.88      0.71      0.77      2591\n",
      "\n",
      "concat titles, texts upostag and texts feats\n",
      "balanced_accuracy: 0.7164585678671667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.67      0.31       246\n",
      "         1.0       0.96      0.72      0.82      2345\n",
      "\n",
      "    accuracy                           0.72      2591\n",
      "   macro avg       0.58      0.70      0.57      2591\n",
      "weighted avg       0.88      0.72      0.78      2591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature(table, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', solver='saga', n_jobs=-1)\n",
    "lr.fit(X(table), y)\n",
    "\n",
    "dump_model(model=lr, scaler=None, path=\"../models/news_model_en.logreg\")\n",
    "pickle.dump(lr, open(\"../models/news_model_en.logreg.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание на неразмеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table_en[flags_na_en]\n",
    "table[\"predict\"] = lr.predict_proba(X(table))[:, 1]\n",
    "\n",
    "b1 = 0.45\n",
    "b2 = 0.55\n",
    "\n",
    "table_middle = table[(table[\"predict\"] > b1) & (table[\"predict\"] < b2)]\n",
    "\n",
    "table_middle = table_middle[[\"path\", \"og:url\", \"predict\"]].join(pd.concat([table_ru[[\"path\", \"og:title\"]], table_en[[\"path\", \"og:title\"]]], \n",
    "                                                                          ignore_index=True, axis=0).set_index(\"path\"), on=\"path\")\n",
    "\n",
    "table_middle = table_middle[[\"og:url\", \"og:title\", \"predict\"]]\n",
    "table_middle[\"is_news\"] = 1\n",
    "\n",
    "table_middle.sort_values(\"predict\").to_excel(\"../articles_with_true_is_news_en.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Копируем таблицу на компьютер \n",
    "\n",
    "scp arina@128.0.134.202:~/Documents/TelegramNews/articles_with_true_is_news_(ru или en).xlsx .\n",
    "\n",
    "Размечаем\n",
    "\n",
    "Копируем обратно \n",
    "\n",
    "scp articles_with_true_is_news_(ru или en).xlsx arina@128.0.134.202:~/Documents/TelegramNews/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_middle = pd.read_excel(\"../articles_with_true_is_news_ru.xlsx\", usecols=[\"og:url\", \"is_news\"])\n",
    "table_middle = table_middle[~table_middle[\"is_news\"].isna()]\n",
    "table_middle = table_middle[:table_middle[\"is_news\"].tolist().index(-1)]\n",
    "\n",
    "#ИЗМЕНИ ИНДЕКС У PART\n",
    "table_middle.to_csv(\"../articles_with_true_is_news/part_1_ru.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_middle = pd.read_excel(\"../articles_with_true_is_news_en.xlsx\", usecols=[\"og:url\", \"is_news\"])\n",
    "table_middle = table_middle[~table_middle[\"is_news\"].isna()]\n",
    "table_middle = table_middle[:table_middle[\"is_news\"].tolist().index(-1)]\n",
    "\n",
    "#ИЗМЕНИ ИНДЕКС У PART\n",
    "table_middle.to_csv(\"../articles_with_true_is_news/part_0_en.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
